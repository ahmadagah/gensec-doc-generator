# 06.1: Code Generation

## 2. Exercise #1: Code generation

- Ask an LLM to generate a prompt that can produce the code above
- Then, in a new chat, send the prompt to the LLM. Does it generate an equivalent piece of code?
- Handcraft a prompt that allows an LLM to generate code that is as close to the original as possible

## 3. Exercise #2: Unit tests

- Ask an LLM to instrument the password program to produce unit tests that can be run to validate code correctness
- Do the unit tests generated provide sufficient coverage for the program?
- Run the generated program and analyze the results for correctness.

## 4. Exercise #3: Type annotation

- Ask an LLM to generate a fully type-annotated version of the program

## 5. Exercise #4: Code editing

- Ask an LLM to convert the password program to into one that uses PBKDF2 with SHA-256 using 100,000 iterations to store hashes into the database rather than cleartext passwords
- After generating the version, have the LLM produce unit tests that validate the implementation. What does it test?
- Test the resulting implementation by running it

## 6. Exercise #5: Code translation

- Ask an LLM to convert the password program from Python to Javascript
- Does the code generated implement the application faithfully?
- Do the tests generated pass?
- Ask an LLM to convert the password program from Python to Typescript
- Does the code generated implement the application faithfully?
- Does the code run successfully?
- Do the tests generated pass?

## 7. Exercise #6: Blind SQL example

- Develop a prompt that allows an LLM to create the above program
- Test the generated program to ensure that it finds the administrator password (but do not solve the level)

## 8. -

- Develop a prompt that produces a binary search implementation of it
- Test the resulting implementation by running it and ensure that the administrator password matches what was found via the linear search
- Solve the level

## 9. Exercise #7: Regular expressions

- Does it generate a correct regular expression?
- If not, reduce the number of strings until it provides one
- What input data can cause an LLM to produce an erroneous expression?

## 10. Exercise #8: Input sanitization (encoding and escaping)

- Safely used as an argument in a Linux command
- Safely included in an HTML document
- Safely included in an HTML attribute (e.g. f' ' )
- Safely included as a URL parameter (e.g. f' https://foo.com/?name={user_input }' )
- Safely included as data in a Javascript program
- Safely included as a field in a CSV (comma separated value) file
- Explain what the code for each example does that prevents attacks

## 11. Exercise #9: Input sanitization (filtering)

- Safely used as an argument in a Linux command
- Safely included in an HTML document
- Safely included in an HTML attribute (e.g. f' ' )
- Safely included as a URL parameter (e.g. f' https://foo.com/?name={user_input }' )
- Safely included as data in a Javascript program
- Safely included as a field in a CSV (comma separated value) file
- Explain what the code for each example does that prevents attacks

## 12. Exercise #10: Documentation generation

- How well does the LLM produce documentation that adheres to each format?
- How well does the LLM produce documentation that adheres to each format?
